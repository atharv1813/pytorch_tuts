{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPFdcXdNxRVqSlj1AVFR2LP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"-uyja8bh1fBV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Core Features\n","\n","1. Tensor Computations  \n","2. GPU Acceleration  \n","3. Dynamic Computation Graph  \n","4. Automatic Differentiation âœ…  \n","5. Distributed Training  \n","6. Interoperability with Other Libraries  \n"],"metadata":{"id":"km6OU2gk1sXh"}},{"cell_type":"markdown","source":["# PyTorch Overview\n","\n","## Open-Source Deep Learning Library\n","- Developed by Meta AI (formerly Facebook AI Research).\n","- Combines Python's ease of use with the efficiency of the Torch scientific computing framework, originally built with Lua.\n","- Torch was known for high-performance tensor-based operations, especially on GPUs.\n","\n","---\n","\n","# PyTorch Release Timeline\n","\n","## PyTorch 0.1 (2017)\n","**Key Features:**\n","- Introduced the dynamic computation graph, enabling more flexible model architectures.\n","- Seamless integration with other Python libraries (e.g., NumPy, SciPy).\n","\n","**Impact:**\n","- Gained popularity among researchers due to its intuitive, Pythonic interface and flexibility.\n","- Quickly featured in numerous research papers.\n","\n","---\n","\n","## PyTorch 1.0 (2018)\n","**Key Features:**\n","- Bridged the gap between research and production environments.\n","- Introduced TorchScript for model serialization and optimization.\n","- Improved performance with Caffe2 integration.\n","\n","**Impact:**\n","- Enabled smoother transitions of models from research to deployment.\n","\n","---\n","\n","## PyTorch 1.x Series\n","**Key Features:**\n","- Support for distributed training.\n","- ONNX compatibility for interoperability with other frameworks.\n","- Introduced quantization for model compression and efficiency.\n","- Expanded ecosystem with:\n","  - `torchvision` (Computer Vision)\n","  - `torchtext` (Natural Language Processing)\n","  - `torchaudio` (Audio)\n","\n","**Impact:**\n","- Increased adoption by both research and industry.\n","- Inspired community libraries like PyTorch Lightning and Hugging Face Transformers.\n","- Strengthened cloud support for easy deployment.\n","\n","---\n","\n","## PyTorch 2.0\n","**Key Features:**\n","- Significant performance improvements.\n","- Enhanced support for deployment and production-readiness.\n","- Optimized for modern hardware (TPUs, custom AI chips).\n","\n","**Impact:**\n","- Improved speed and scalability for real-world applications.\n","- Better compatibility with a variety of deployment environments.\n"],"metadata":{"id":"_prwvtRn1gSj"}},{"cell_type":"code","source":[],"metadata":{"id":"4p4mBMzo1hAP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PyTorch vs TensorFlow Comparison\n","\n","| **Aspect**                   | **PyTorch**                                                                                              | **TensorFlow**                                                                                           | **Verdict**                                                                                 |\n","|------------------------------|----------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|\n","| **Programming Language**     | Primarily Python; provides a Pythonic interface with deep integration.                                  | Supports multiple languages: Python (primary), C++, Java, JavaScript (TensorFlow.js), and Swift (experimental). | **Depends**: PyTorch for Python-centric development; TensorFlow for multi-language support. |\n","| **Ease of Use**              | Known for its intuitive and Pythonic syntax, making it user-friendly and easier for beginners.          | TensorFlow 2.x improved usability with Keras integration, but can still be complex.                       | **PyTorch Wins**: Generally considered easier to learn and more intuitive.                  |\n","| **Deployment & Production**  | Offers TorchScript for model serialization; PyTorch Mobile supports mobile deployment; growing support for production environments. | Strong production support with TensorFlow Serving, TensorFlow Lite, and TensorFlow.js; more mature tools. | **TensorFlow Wins**: More mature and comprehensive deployment infrastructure.              |\n","| **Performance**              | Competitive performance; dynamic graphs may introduce slight overhead; optimized with TorchScript and JIT compilation. | Optimized through static graphs and XLA compiler; efficient for large-scale models.                      | **Tie**: Performance differences are generally negligible in practice.                      |\n","| **High-Level APIs**          | Uses native modules like `torch.nn`; high-level interfaces provided by PyTorch Lightning and Fast.ai.   | Integrates `tf.keras` as the high-level API.                                                              | **TensorFlow Wins**: Keras provides a more established and user-friendly high-level API.    |\n","| **Mobile & Embedded Deployment** | PyTorch Mobile enables deployment on iOS and Android; supports model optimization like quantization. | TensorFlow Lite provides robust support for mobile and embedded devices; TensorFlow.js for web deployment. | **TensorFlow Wins**: More mature and versatile options for mobile and embedded deployment.  |\n","| **Preferred Domains**        | Favored in research and academia; excels in rapid prototyping; strong in computer vision and NLP tasks. | Widely used in industry and production; versatile across various domains.                                 | **Depends**: PyTorch for research; TensorFlow for industry applications.                    |\n","| **Learning Curve**           | Easier to learn due to intuitive design and dynamic execution.                                           | Improved in TensorFlow 2.x but still has a steeper learning curve.                                        | **PyTorch Wins**: More beginner-friendly.                                                   |\n","| **Interoperability**         | Seamless integration with Python libraries; supports exporting models to ONNX format.                   | Interoperable through TensorFlow Hub and SavedModel; supports ONNX with some limitations.                 | **PyTorch Wins**: Better integration with the Python ecosystem.                             |\n","| **Customizability**          | High level of customization; easy to write custom layers and training loops.                            | Custom operations possible but more complex due to static graph structure.                                | **PyTorch Wins**: Easier and more flexible for custom model design.                         |\n","| **Deployment Tools**         | TorchServe for model serving; integrates with AWS, Azure, and Google Cloud.                            | TensorFlow Serving, TensorFlow Extended (TFX) for ML pipelines; strong cloud support.                     | **TensorFlow Wins**: More mature deployment tools and pipeline support.                     |\n","| **Parallelism & Distributed Training** | Supports distributed training with `torch.distributed`; enhanced by libraries like Horovod.       | Extensive support with `tf.distribute.Strategy`; optimized for large-scale computing.                     | **TensorFlow Wins**: Better built-in support for distributed training.                      |\n","| **Model Zoo & Pre-trained Models** | Access via TorchVision, Hugging Face; strong community sharing.                                    | TensorFlow Hub offers a wide range; extensive community models.                                           | **Tie**: Both offer excellent pre-trained model support; choice depends on specific needs.  |\n"],"metadata":{"id":"esv20hwt1wSm"}},{"cell_type":"code","source":[],"metadata":{"id":"BmzGpdCs19rx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Core PyTorch Modules\n","\n","| **Module**               | **Description**                                                                                                                                           |\n","|--------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| `torch`                  | The core module providing multidimensional arrays (tensors) and mathematical operations on them.                                                         |\n","| `torch.autograd`         | Automatic differentiation engine that records operations on tensors to compute gradients for optimization.                                               |\n","| `torch.nn`               | Provides a neural networks library, including layers, activations, loss functions, and utilities to build deep learning models.                          |\n","| `torch.optim`            | Contains optimization algorithms (optimizers) like SGD, Adam, and RMSprop used for training neural networks.                                             |\n","| `torch.utils.data`       | Utilities for data handling, including the `Dataset` and `DataLoader` classes for managing and loading datasets efficiently.                             |\n","| `torch.jit`              | Supports Just-In-Time (JIT) compilation and TorchScript for optimizing models and enabling deployment without Python dependencies.                       |\n","| `torch.distributed`      | Tools for distributed training across multiple GPUs and machines, facilitating parallel computation.                                                     |\n","| `torch.cuda`             | Interfaces with NVIDIA CUDA to enable GPU acceleration for tensor computations and model training.                                                       |\n","| `torch.backends`         | Contains settings and allows control over backend libraries like cuDNN, MKL, and others for performance tuning.                                          |\n","| `torch.multiprocessing`  | Utilities for parallelism using multiprocessing, similar to Python's `multiprocessing` module but with support for CUDA tensors.                          |\n","| `torch.quantization`     | Tools for model quantization to reduce model size and improve inference speed, especially on edge devices.                                               |\n","| `torch.onnx`             | Supports exporting PyTorch models to the ONNX (Open Neural Network Exchange) format for interoperability with other frameworks and deployment tools.     |\n"],"metadata":{"id":"X_xF7U303Akr"}},{"cell_type":"code","source":[],"metadata":{"id":"p2THkLSa3Qt2"},"execution_count":null,"outputs":[]}]}